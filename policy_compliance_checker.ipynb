{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Policy Compliance Checker with Human-in-the-Loop\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll build an automated compliance checker that reviews documents against organizational policies. More importantly, you'll learn about **human-in-the-loop (HIL)** workflows and understand why they're essential for real-world AI applications.\n",
    "\n",
    "## Why Human-in-the-Loop Matters\n",
    "\n",
    "Imagine you work in an organization where policy changes happen frequently. You might need to review hundreds of documents to ensure they all comply with new requirements. An AI agent could scan these documents automatically, but what if it makes a mistake? What if a document is ambiguous and could be interpreted multiple ways?\n",
    "\n",
    "**Human-in-the-loop workflows solve this problem** by allowing an AI agent to:\n",
    "1. Do the tedious work of scanning and flagging potential issues\n",
    "2. **Pause and ask for human confirmation** before taking action\n",
    "3. Continue processing based on human feedback\n",
    "\n",
    "This combines the efficiency of automation with the judgment of human expertise.\n",
    "\n",
    "## What is LangGraph?\n",
    "\n",
    "**LangGraph** is a framework for building stateful, multi-step AI applications (often called \"agents\"). Think of it as a way to create workflows where:\n",
    "- Your AI can perform multiple steps in sequence\n",
    "- The AI can remember what happened in previous steps\n",
    "- You can pause the workflow and resume it later\n",
    "- You can insert human decision points exactly where you need them\n",
    "\n",
    "It's particularly powerful for tasks that require multiple decisions or where you need to maintain context across several operations.\n",
    "\n",
    "## Our Scenario\n",
    "\n",
    "We'll build a policy compliance checker that verifies official documents contain specific metadata meeting these requirements:\n",
    "\n",
    "- **Title**: Required, cannot be blank\n",
    "- **Last Updated**: Required, must be in YYYY-MM-DD format\n",
    "- **Reviewed By**: Required, must contain at least one reviewer name (first and last)\n",
    "- **Status**: Required, must be one of: Draft, Final, or Archived\n",
    "- **Version**: Required, must be in semantic version format (e.g., 1.0.0)\n",
    "\n",
    "We'll build this in two stages:\n",
    "1. **Pattern matching version**: Fast, simple, but very rigid\n",
    "2. **LLM-enhanced version**: Smarter at handling ambiguity, but still needs human oversight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "First, let's install the packages we need using conda. We're using:\n",
    "- **langgraph**: The framework for building our stateful workflow\n",
    "- **langchain_anthropic**: To connect to Claude for the LLM-enhanced version\n",
    "\n",
    "Both packages are available on conda-forge, which is the community-led collection of recipes for the conda package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages using conda\n",
    "# The -y flag automatically confirms the installation and the -q flag makes conda run quietly\n",
    "%conda install -c conda-forge langgraph langchain-anthropic -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "import re\n",
    "from typing import Annotated\n",
    "from pathlib import Path\n",
    "\n",
    "# LangGraph imports - each will be explained as it is used\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command, interrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key Setup (Optional for Part 1)\n",
    "\n",
    "**Note**: You don't need an API key to run Part 1 (pattern matching version). You'll only need an Anthropic API key for Part 2 if you want to try the LLM-enhanced version.\n",
    "\n",
    "To get an API key:\n",
    "1. Sign up at https://console.anthropic.com\n",
    "2. Navigate to API Keys\n",
    "3. Create a new key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function safely prompts for an API key if one isn't already set\n",
    "def set_api_key(key_name: str):\n",
    "    \"\"\"Prompt for API key if not already set in environment.\"\"\"\n",
    "    if not os.environ.get(key_name):\n",
    "        os.environ[key_name] = getpass.getpass(f\"{key_name}: \")\n",
    "\n",
    "# Uncomment the line below when you're ready to try Part 2\n",
    "set_api_key(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample Documents\n",
    "\n",
    "Let's create a few sample documents that represent different compliance scenarios. We'll save these as markdown files so you can easily see their content and modify them if you want to experiment.\n",
    "\n",
    "We'll create:\n",
    "1. A **compliant** document that meets all requirements\n",
    "2. A document with **missing fields**\n",
    "3. A document with an **ambiguous entry** that could be interpreted different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: sample_documents/data_retention.md\n",
      "Created: sample_documents/employee_handbook.md\n",
      "Created: sample_documents/security_protocols.md\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to store our sample documents\n",
    "docs_dir = Path(\"sample_documents\")\n",
    "docs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Document 1: Fully compliant\n",
    "compliant_doc = \"\"\"---\n",
    "Title: Data Retention Policy\n",
    "Last Updated: 2024-11-01\n",
    "Reviewed By: Sarah Chen\n",
    "Status: Final\n",
    "Version: 2.1.0\n",
    "---\n",
    "\n",
    "# Data Retention Policy\n",
    "\n",
    "This policy outlines the requirements for data retention across all departments.\n",
    "\"\"\"\n",
    "\n",
    "# Document 2: Missing required fields\n",
    "missing_fields_doc = \"\"\"---\n",
    "Title: Employee Handbook\n",
    "Last Updated: 2024-10-15\n",
    "---\n",
    "\n",
    "# Employee Handbook\n",
    "\n",
    "Welcome to the company! This handbook contains important information.\n",
    "\"\"\"\n",
    "\n",
    "# Document 3: Ambiguous Reviewer Name (human judgment needed)\n",
    "ambiguous_name_doc = \"\"\"---\n",
    "Title: Security Protocols\n",
    "Last Updated: 2024-09-20\n",
    "Reviewed By: Legal Team\n",
    "Status: Final\n",
    "Version: 3.2.1\n",
    "---\n",
    "\n",
    "# Security Protocols\n",
    "\n",
    "Critical security measures for all staff.\n",
    "\"\"\"\n",
    "\n",
    "# Save all documents to files\n",
    "documents = {\n",
    "    \"data_retention.md\": compliant_doc,\n",
    "    \"employee_handbook.md\": missing_fields_doc,\n",
    "    \"security_protocols.md\": ambiguous_name_doc\n",
    "}\n",
    "\n",
    "for filename, content in documents.items():\n",
    "    filepath = docs_dir / filename\n",
    "    filepath.write_text(content)\n",
    "    print(f\"Created: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pattern Matching Version\n",
    "\n",
    "Let's start with a simple version that uses pattern matching (regular expressions) to check compliance. This approach is:\n",
    "- **Fast**: No API calls needed\n",
    "- **Deterministic**: Same input always gives same output\n",
    "- **Free**: No API costs\n",
    "\n",
    "But it's also **rigid**: It can't understand context or handle ambiguity.\n",
    "\n",
    "### Understanding LangGraph Concepts\n",
    "\n",
    "Before we build our workflow, let's understand the key concepts:\n",
    "\n",
    "#### 1. State\n",
    "**State** is the data that flows through your workflow. Think of it as a shared notebook that every step can read from and write to. In our case, the state will track:\n",
    "- Which documents we're checking\n",
    "- What violations we've found\n",
    "- What the human decided about flagged documents\n",
    "\n",
    "#### 2. Nodes\n",
    "**Nodes** are the individual steps in your workflow. Each node is a function that:\n",
    "- Receives the current state\n",
    "- Does some work\n",
    "- Returns updates to the state\n",
    "\n",
    "#### 3. Edges\n",
    "**Edges** connect nodes together, defining the flow of execution. They determine which node runs next.\n",
    "\n",
    "#### 4. Checkpointer\n",
    "A **checkpointer** saves the state at each step. This is crucial for human-in-the-loop workflows because it lets us:\n",
    "- Pause execution\n",
    "- Wait for human input\n",
    "- Resume exactly where we left off\n",
    "\n",
    "Think of it like saving your progress in a video game.\n",
    "\n",
    "#### 5. Interrupt\n",
    "The **interrupt()** function pauses execution and waits for human input. It's the key to human-in-the-loop workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our State\n",
    "\n",
    "First, let's define what information our workflow needs to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class ComplianceState(TypedDict):\n",
    "    \"\"\"State that tracks our compliance checking workflow.\n",
    "    \n",
    "    This dictionary will be passed between all nodes in our graph.\n",
    "    Each node can read from it and update it.\n",
    "    \"\"\"\n",
    "    # List of document filenames to check\n",
    "    documents_to_check: list[str]\n",
    "    \n",
    "    # Index of the current document we're processing\n",
    "    current_document_index: int\n",
    "    \n",
    "    # Results of our compliance checks\n",
    "    # Each entry is a dict with: filename, compliant (bool), issues (list)\n",
    "    results: list[dict]\n",
    "    \n",
    "    # When we find a potential violation, we store it here to show the human\n",
    "    pending_review: dict | None\n",
    "    \n",
    "    # Whether we're finished checking all documents\n",
    "    complete: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Compliance Checker Function\n",
    "\n",
    "Now let's create a function that checks if a document meets our policy requirements using pattern matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_document_compliance_pattern_matching(filepath: Path) -> dict:\n",
    "    \"\"\"Check if a document meets compliance requirements using pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the markdown document to check\n",
    "        \n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            - filename: Name of the file\n",
    "            - compliant: True if all requirements met\n",
    "            - issues: List of compliance issues found\n",
    "            - metadata: The extracted metadata\n",
    "    \"\"\"\n",
    "    content = filepath.read_text()\n",
    "    issues = []\n",
    "    \n",
    "    # Extract the metadata section (between the --- markers)\n",
    "    metadata_match = re.search(r'^---\\s*\\n(.*?)\\n---', content, re.MULTILINE | re.DOTALL)\n",
    "    \n",
    "    if not metadata_match:\n",
    "        return {\n",
    "            \"filename\": filepath.name,\n",
    "            \"compliant\": False,\n",
    "            \"issues\": [\"No metadata section found\"],\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "    \n",
    "    metadata_text = metadata_match.group(1)\n",
    "    \n",
    "    # Parse metadata into a dictionary\n",
    "    metadata = {}\n",
    "    for line in metadata_text.split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    # Check each requirement\n",
    "    \n",
    "    # 1. Title: Required and cannot be blank\n",
    "    if 'Title' not in metadata:\n",
    "        issues.append(\"Missing required field: Title\")\n",
    "    elif not metadata['Title'] or metadata['Title'].strip() == '':\n",
    "        issues.append(\"Title field cannot be blank\")\n",
    "    \n",
    "    # 2. Last Updated: Required and must be YYYY-MM-DD format\n",
    "    if 'Last Updated' not in metadata:\n",
    "        issues.append(\"Missing required field: Last Updated\")\n",
    "    else:\n",
    "        # Check for YYYY-MM-DD format using regex\n",
    "        date_pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "        if not re.match(date_pattern, metadata['Last Updated']):\n",
    "            issues.append(f\"Last Updated must be in YYYY-MM-DD format (found: '{metadata['Last Updated']}')\")\n",
    "    \n",
    "    # 3. Reviewed By: Required and must have at least one name\n",
    "    if 'Reviewed By' not in metadata:\n",
    "        issues.append(\"Missing required field: Reviewed By\")\n",
    "    elif not metadata['Reviewed By'] or metadata['Reviewed By'].strip() == '':\n",
    "        issues.append(\"Reviewed By cannot be blank\")\n",
    "    else:\n",
    "        # Check that Reviewed By has at least two words (first and last name)\n",
    "        if len(metadata['Reviewed By'].split()) < 2:\n",
    "            issues.append(\"Reviewed By must include at least a first and last name\")\n",
    "    \n",
    "    # 4. Status: Required and must be Draft, Final, or Archived\n",
    "    valid_statuses = ['Draft', 'Final', 'Archived']\n",
    "    if 'Status' not in metadata:\n",
    "        issues.append(\"Missing required field: Status\")\n",
    "    elif metadata['Status'] not in valid_statuses:\n",
    "        issues.append(f\"Status must be one of {valid_statuses} (found: '{metadata['Status']}')\")\n",
    "    \n",
    "    # 5. Version: Required and should be semantic version format\n",
    "    if 'Version' not in metadata:\n",
    "        issues.append(\"Missing required field: Version\")\n",
    "    else:\n",
    "        # Check for semantic version format (e.g., 1.0.0)\n",
    "        version_pattern = r'^\\d+\\.\\d+\\.\\d+$'\n",
    "        if not re.match(version_pattern, metadata['Version']):\n",
    "            issues.append(f\"Version should be in semantic version format like 1.0.0 (found: '{metadata['Version']}')\")\n",
    "    \n",
    "    return {\n",
    "        \"filename\": filepath.name,\n",
    "        \"compliant\": len(issues) == 0,\n",
    "        \"issues\": issues,\n",
    "        \"metadata\": metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function on one of our documents to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: employee_handbook.md\n",
      "Compliant: False\n",
      "Issues found: ['Missing required field: Reviewed By', 'Missing required field: Status', 'Missing required field: Version']\n",
      "Metadata: {'Title': 'Employee Handbook', 'Last Updated': '2024-10-15'}\n"
     ]
    }
   ],
   "source": [
    "# Test on the missing fields document\n",
    "test_result = check_document_compliance_pattern_matching(docs_dir / \"employee_handbook.md\")\n",
    "print(f\"Document: {test_result['filename']}\")\n",
    "print(f\"Compliant: {test_result['compliant']}\")\n",
    "print(f\"Issues found: {test_result['issues']}\")\n",
    "print(f\"Metadata: {test_result['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Workflow Nodes\n",
    "\n",
    "Now let's create the nodes (steps) that make up our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_next_document(state: ComplianceState) -> ComplianceState:\n",
    "    \"\"\"Node that checks the next document in our queue.\n",
    "    \n",
    "    This node:\n",
    "    1. Gets the next document to check\n",
    "    2. Runs compliance checks on it\n",
    "    3. If issues found, stores them for human review\n",
    "    4. If no issues, marks it as compliant\n",
    "    \"\"\"\n",
    "    current_idx = state[\"current_document_index\"]\n",
    "    documents = state[\"documents_to_check\"]\n",
    "    \n",
    "    # Check if we've processed all documents\n",
    "    if current_idx >= len(documents):\n",
    "        state[\"complete\"] = True\n",
    "        return state\n",
    "    \n",
    "    # Get the current document and check it\n",
    "    current_file = documents[current_idx]\n",
    "    filepath = Path(\"sample_documents\") / current_file\n",
    "    \n",
    "    print(f\"\\n Checking: {current_file}\")\n",
    "    \n",
    "    result = check_document_compliance_pattern_matching(filepath)\n",
    "    \n",
    "    # If the document is not compliant, we need human review\n",
    "    if not result[\"compliant\"]:\n",
    "        print(f\"Issues found! Flagging for human review...\")\n",
    "        state[\"pending_review\"] = result\n",
    "    else:\n",
    "        print(f\"Document is compliant!\")\n",
    "        state[\"results\"].append(result)\n",
    "        # Move to next document\n",
    "        state[\"current_document_index\"] += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def human_review(state: ComplianceState) -> ComplianceState:\n",
    "    \"\"\"Node that pauses for human review of flagged documents.\n",
    "    \n",
    "    This is where the magic happens! We use interrupt() to pause execution\n",
    "    and wait for a human decision.\n",
    "    \"\"\"\n",
    "    pending = state[\"pending_review\"]\n",
    "    \n",
    "    if pending is None:\n",
    "        # Nothing to review, continue\n",
    "        return state\n",
    "    \n",
    "    # Display the issues to the human\n",
    "    print(f\"\\n Document '{pending['filename']}' flagged for review:\")\n",
    "    for issue in pending['issues']:\n",
    "        print(f\"   - {issue}\")\n",
    "    \n",
    "    # Only show metadata if it exists (pattern matching version has it, LLM version doesn't)\n",
    "    if 'metadata' in pending:\n",
    "        print(\"\\nMetadata found:\")\n",
    "        for key, value in pending['metadata'].items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # If we have LLM analysis, show that instead\n",
    "    if 'llm_analysis' in pending:\n",
    "        print(\"\\nLLM Analysis:\")\n",
    "        print(pending['llm_analysis'])\n",
    "    \n",
    "    # This is the key line! interrupt() pauses execution here.\n",
    "    # The workflow won't continue until we resume it with a human decision.\n",
    "    human_decision = interrupt(\n",
    "        \"Is this a compliance violation? Reply 'yes' to confirm or 'no' if this is acceptable.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n Human decision: {human_decision}\")\n",
    "    \n",
    "    # Record the decision\n",
    "    if human_decision.lower() == 'yes':\n",
    "        print(\"   → Marking as non-compliant\")\n",
    "        pending[\"human_confirmed\"] = True\n",
    "    else:\n",
    "        print(\"   → Marking as compliant (false positive)\")\n",
    "        pending[\"compliant\"] = True\n",
    "        pending[\"issues\"] = []  # Clear issues since human approved it\n",
    "        pending[\"human_confirmed\"] = False\n",
    "    \n",
    "    # Add to results and move to next document\n",
    "    state[\"results\"].append(pending)\n",
    "    state[\"pending_review\"] = None\n",
    "    state[\"current_document_index\"] += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def should_continue(state: ComplianceState) -> str:\n",
    "    \"\"\"Conditional edge that determines where to go next.\n",
    "    \n",
    "    This function decides the next step based on the current state:\n",
    "    - If we're done checking all documents, end the workflow\n",
    "    - If there's a document pending human review, go to human_review\n",
    "    - Otherwise, check the next document\n",
    "    \"\"\"\n",
    "    if state[\"complete\"]:\n",
    "        return \"end\"\n",
    "    elif state[\"pending_review\"] is not None:\n",
    "        return \"review\"\n",
    "    else:\n",
    "        return \"check\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Graph\n",
    "\n",
    "Now we'll assemble all the pieces into a LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compliance checker workflow built successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the graph builder\n",
    "# StateGraph takes our state type as a parameter\n",
    "workflow = StateGraph(ComplianceState)\n",
    "\n",
    "# Add our nodes to the graph\n",
    "# The string names are how we'll reference these nodes when defining edges\n",
    "workflow.add_node(\"check_document\", check_next_document)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "\n",
    "# Define the starting point\n",
    "# START is a special constant that marks where execution begins\n",
    "workflow.add_edge(START, \"check_document\")\n",
    "\n",
    "# Add conditional edges based on the should_continue function\n",
    "# This function determines which node to go to next\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_document\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"check\": \"check_document\",  # Check another document\n",
    "        \"review\": \"human_review\",    # Need human review\n",
    "        \"end\": END                    # All done\n",
    "    }\n",
    ")\n",
    "\n",
    "# After human review, go back to checking documents\n",
    "workflow.add_edge(\"human_review\", \"check_document\")\n",
    "\n",
    "# Create a checkpointer to save our progress\n",
    "# MemorySaver stores checkpoints in memory (good for demos)\n",
    "# For production, you'd use a persistent storage backend\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph into a runnable application\n",
    "# The checkpointer parameter enables the pause/resume functionality\n",
    "compliance_checker = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"Compliance checker workflow built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Compliance Checker\n",
    "\n",
    "Now let's run our workflow! Watch how it:\n",
    "1. Checks each document\n",
    "2. Pauses when it finds issues\n",
    "3. Waits for your decision\n",
    "4. Continues based on your input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compliance check...\n",
      "\n",
      "============================================================\n",
      "\n",
      " Checking: data_retention.md\n",
      "Document is compliant!\n",
      "\n",
      " Checking: employee_handbook.md\n",
      "Issues found! Flagging for human review...\n",
      "\n",
      " Document 'employee_handbook.md' flagged for review:\n",
      "   - Missing required field: Reviewed By\n",
      "   - Missing required field: Status\n",
      "   - Missing required field: Version\n",
      "\n",
      "Metadata found:\n",
      "   Title: Employee Handbook\n",
      "   Last Updated: 2024-10-15\n"
     ]
    }
   ],
   "source": [
    "# Set up the initial state\n",
    "initial_state = {\n",
    "    \"documents_to_check\": [\n",
    "        \"data_retention.md\",\n",
    "        \"employee_handbook.md\",\n",
    "        \"security_protocols.md\"\n",
    "    ],\n",
    "    \"current_document_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"pending_review\": None,\n",
    "    \"complete\": False\n",
    "}\n",
    "\n",
    "# Configuration for this run\n",
    "# The thread_id identifies this particular workflow instance\n",
    "# Think of it like a session ID - we can pause and resume using this ID\n",
    "config = {\"configurable\": {\"thread_id\": \"compliance-check-1\"}}\n",
    "\n",
    "print(\"Starting compliance check...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start the workflow\n",
    "# This will run until it hits an interrupt() or completes\n",
    "for event in compliance_checker.stream(initial_state, config):\n",
    "    pass  # The nodes handle their own printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding What Just Happened\n",
    "\n",
    "The workflow should have paused after finding the first non-compliant document. Let's check the current state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current workflow state:\n",
      "  - Documents checked so far: 1\n",
      "  - Waiting for human review: True\n",
      "  - Next node to execute: ('human_review',)\n"
     ]
    }
   ],
   "source": [
    "# Get the current state of our workflow\n",
    "current_state = compliance_checker.get_state(config)\n",
    "\n",
    "print(\"Current workflow state:\")\n",
    "print(f\"  - Documents checked so far: {current_state.values['current_document_index']}\")\n",
    "print(f\"  - Waiting for human review: {current_state.values['pending_review'] is not None}\")\n",
    "print(f\"  - Next node to execute: {current_state.next}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing Human Feedback\n",
    "\n",
    "Now we can provide our decision (\"yes\" to agree that there is a policy violation) and let the workflow continue. We use `Command(resume=...)` to provide our answer to the `interrupt()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Providing human feedback: 'yes' (confirming violation)\n",
      "\n",
      "\n",
      " Document 'employee_handbook.md' flagged for review:\n",
      "   - Missing required field: Reviewed By\n",
      "   - Missing required field: Status\n",
      "   - Missing required field: Version\n",
      "\n",
      "Metadata found:\n",
      "   Title: Employee Handbook\n",
      "   Last Updated: 2024-10-15\n",
      "\n",
      " Human decision: yes\n",
      "   → Marking as non-compliant\n",
      "\n",
      " Checking: security_protocols.md\n",
      "Document is compliant!\n"
     ]
    }
   ],
   "source": [
    "# Provide human feedback: confirm this is a violation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Providing human feedback: 'yes' (confirming violation)\\n\")\n",
    "\n",
    "# Resume the workflow with our decision\n",
    "# Command(resume=\"yes\") sends \"yes\" to the interrupt() call\n",
    "for event in compliance_checker.stream(Command(resume=\"yes\"), config):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow would pause again if it found another document with issues, but in this case our very rigid regex method was not able to detect that there was ambiguity with the metadata for our final document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Final Results\n",
    "\n",
    "Now let's look at our final compliance report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPLIANCE CHECK COMPLETE\n",
      "============================================================\n",
      "\n",
      "Summary: 2/3 documents compliant\n",
      "\n",
      "COMPLIANT: data_retention.md\n",
      "\n",
      "NON-COMPLIANT: employee_handbook.md\n",
      "  Issues:\n",
      "    - Missing required field: Reviewed By\n",
      "    - Missing required field: Status\n",
      "    - Missing required field: Version\n",
      "  Human confirmed violation\n",
      "\n",
      "COMPLIANT: security_protocols.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the final state\n",
    "final_state = compliance_checker.get_state(config)\n",
    "results = final_state.values[\"results\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPLIANCE CHECK COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "compliant_count = sum(1 for r in results if r[\"compliant\"])\n",
    "total_count = len(results)\n",
    "\n",
    "print(f\"\\nSummary: {compliant_count}/{total_count} documents compliant\\n\")\n",
    "\n",
    "for result in results:\n",
    "    status = \"COMPLIANT\" if result[\"compliant\"] else \"NON-COMPLIANT\"\n",
    "    print(f\"{status}: {result['filename']}\")\n",
    "    \n",
    "    if not result[\"compliant\"]:\n",
    "        print(\"  Issues:\")\n",
    "        for issue in result[\"issues\"]:\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    # Show if human overrode the decision\n",
    "    if \"human_confirmed\" in result:\n",
    "        if result[\"human_confirmed\"]:\n",
    "            print(\"  Human confirmed violation\")\n",
    "        else:\n",
    "            print(\"  Human marked as false positive\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of Pattern Matching\n",
    "\n",
    "Notice how our pattern matching approach was unable to recognize \"Legal Team\" as non-compliant even though a human might recognize this as an invalid name? This is where an LLM could help!\n",
    "\n",
    "Pattern matching is:\n",
    "- Fast and free\n",
    "- Predictable and deterministic\n",
    "- Can't understand context\n",
    "- Can't handle ambiguity\n",
    "\n",
    "Let's see how we can improve this with an LLM..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: LLM-Enhanced Version\n",
    "\n",
    "Now let's upgrade our compliance checker to use Claude (an LLM) for analysis. This will help us:\n",
    "- Handle ambiguous cases better\n",
    "- Understand context and intent\n",
    "- Provide more nuanced analysis\n",
    "\n",
    "**But here's the key insight**: Even with an LLM, we still use human-in-the-loop! Why?\n",
    "- LLMs can still make mistakes\n",
    "- Compliance decisions often have legal/business implications\n",
    "- Humans provide accountability and final judgment\n",
    "\n",
    "### Setting Up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized\n"
     ]
    }
   ],
   "source": [
    "# Make sure you've set your API key (run this if you haven't already)\n",
    "set_api_key(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Initialize Claude\n",
    "# We're using claude-sonnet-4-5-20250929 which is fast and cost-effective\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0  # Low temperature for consistent, deterministic responses\n",
    ")\n",
    "\n",
    "print(\"LLM initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an LLM-Based Checker\n",
    "\n",
    "Let's create a new compliance checker function that uses Claude to analyze documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_document_compliance_llm(filepath: Path) -> dict:\n",
    "    \"\"\"Check document compliance using an LLM for more nuanced analysis.\n",
    "    \n",
    "    The LLM can understand context and handle ambiguity better than\n",
    "    simple pattern matching.\n",
    "    \"\"\"\n",
    "    content = filepath.read_text()\n",
    "    \n",
    "    # Create a prompt that explains our requirements clearly\n",
    "    prompt = f\"\"\"You are a document compliance analyst. Review the following document and check if it meets these metadata requirements:\n",
    "\n",
    "REQUIRED METADATA:\n",
    "1. Title: Must be present and cannot be blank\n",
    "2. Last Updated: Must be present in YYYY-MM-DD format (e.g., 2024-11-01)\n",
    "3. Reviewed By: Must be present with at least one reviewer name (first and last)\n",
    "4. Status: Must be present and be one of: Draft, Final, or Archived\n",
    "5. Version: Must be present in semantic version format (e.g., 1.0.0)\n",
    "\n",
    "DOCUMENT TO REVIEW:\n",
    "{content}\n",
    "\n",
    "Analyze this document and respond in this exact format:\n",
    "\n",
    "COMPLIANT: [yes or no]\n",
    "ISSUES:\n",
    "- [list each compliance issue on a separate line, or write \"None\" if compliant]\n",
    "\n",
    "Use good judgment for ambiguous cases. For example, a Title that is just letters that do not form words would not be compliant.\n",
    "\"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    response_text = response.content\n",
    "    \n",
    "    # Parse the LLM's response\n",
    "    compliant = \"COMPLIANT: yes\" in response_text\n",
    "    \n",
    "    # Extract issues from the response\n",
    "    issues = []\n",
    "    if \"ISSUES:\" in response_text:\n",
    "        issues_section = response_text.split(\"ISSUES:\")[1].strip()\n",
    "        issues = [\n",
    "            line.strip(\"- \").strip() \n",
    "            for line in issues_section.split(\"\\n\") \n",
    "            if line.strip() and line.strip() != \"None\"\n",
    "        ]\n",
    "    \n",
    "    return {\n",
    "        \"filename\": filepath.name,\n",
    "        \"compliant\": compliant,\n",
    "        \"issues\": issues,\n",
    "        \"llm_analysis\": response_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this on our ambiguous name document to see how the LLM handles it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full LLM Analysis:\n",
      "COMPLIANT: no\n",
      "ISSUES:\n",
      "- Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n"
     ]
    }
   ],
   "source": [
    "# Test on the ambiguous document\n",
    "llm_result = check_document_compliance_llm(docs_dir / \"security_protocols.md\")\n",
    "#print(f\"Document: {llm_result['filename']}\")\n",
    "#print(f\"Compliant: {llm_result['compliant']}\")\n",
    "#print(f\"Issues: {llm_result['issues']}\")\n",
    "print(f\"\\nFull LLM Analysis:\\n{llm_result['llm_analysis']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM was able to successfully determine that \"Legal Team\" is not a valid name!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LLM-Enhanced Workflow\n",
    "\n",
    "Now let's create a new version of our workflow that uses the LLM checker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-enhanced compliance checker workflow built successfully!\n"
     ]
    }
   ],
   "source": [
    "def check_next_document_llm(state: ComplianceState) -> ComplianceState:\n",
    "    \"\"\"LLM-enhanced version of document checking node.\"\"\"\n",
    "    current_idx = state[\"current_document_index\"]\n",
    "    documents = state[\"documents_to_check\"]\n",
    "    \n",
    "    if current_idx >= len(documents):\n",
    "        state[\"complete\"] = True\n",
    "        return state\n",
    "    \n",
    "    current_file = documents[current_idx]\n",
    "    filepath = Path(\"sample_documents\") / current_file\n",
    "    \n",
    "    print(f\"\\n Checking with LLM: {current_file}\")\n",
    "    \n",
    "    # Use LLM-based checking instead of pattern matching\n",
    "    result = check_document_compliance_llm(filepath)\n",
    "    \n",
    "    if not result[\"compliant\"]:\n",
    "        print(f\"Issues found! Flagging for human review...\")\n",
    "        state[\"pending_review\"] = result\n",
    "    else:\n",
    "        print(f\"Document is compliant!\")\n",
    "        state[\"results\"].append(result)\n",
    "        state[\"current_document_index\"] += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Build the new workflow (same structure, different checker)\n",
    "workflow_llm = StateGraph(ComplianceState)\n",
    "workflow_llm.add_node(\"check_document\", check_next_document_llm)\n",
    "workflow_llm.add_node(\"human_review\", human_review)  # Reuse same review node\n",
    "\n",
    "workflow_llm.add_edge(START, \"check_document\")\n",
    "workflow_llm.add_conditional_edges(\n",
    "    \"check_document\",\n",
    "    should_continue,  # Reuse same conditional logic\n",
    "    {\n",
    "        \"check\": \"check_document\",\n",
    "        \"review\": \"human_review\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "workflow_llm.add_edge(\"human_review\", \"check_document\")\n",
    "\n",
    "# Create a new checkpointer for this workflow\n",
    "checkpointer_llm = MemorySaver()\n",
    "compliance_checker_llm = workflow_llm.compile(checkpointer=checkpointer_llm)\n",
    "\n",
    "print(\"LLM-enhanced compliance checker workflow built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the LLM-Enhanced Checker\n",
    "\n",
    "Let's run the same documents through our LLM-enhanced workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LLM-enhanced compliance check...\n",
      "\n",
      "============================================================\n",
      "\n",
      " Checking with LLM: data_retention.md\n",
      "Document is compliant!\n",
      "\n",
      " Checking with LLM: employee_handbook.md\n",
      "Issues found! Flagging for human review...\n",
      "\n",
      " Document 'employee_handbook.md' flagged for review:\n",
      "   - Reviewed By: Missing - no reviewer name present\n",
      "   - Status: Missing - must be Draft, Final, or Archived\n",
      "   - Version: Missing - must be in semantic version format (e.g., 1.0.0)\n",
      "\n",
      "LLM Analysis:\n",
      "COMPLIANT: no\n",
      "ISSUES:\n",
      "- Reviewed By: Missing - no reviewer name present\n",
      "- Status: Missing - must be Draft, Final, or Archived\n",
      "- Version: Missing - must be in semantic version format (e.g., 1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Reset state for the new run\n",
    "initial_state_llm = {\n",
    "    \"documents_to_check\": [\n",
    "        \"data_retention.md\",\n",
    "        \"employee_handbook.md\",\n",
    "        \"security_protocols.md\"\n",
    "    ],\n",
    "    \"current_document_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"pending_review\": None,\n",
    "    \"complete\": False\n",
    "}\n",
    "\n",
    "# Fresh thread ID\n",
    "config_llm = {\"configurable\": {\"thread_id\": \"compliance-check-llm-6\"}}\n",
    "\n",
    "print(\"Starting LLM-enhanced compliance check...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for event in compliance_checker_llm.stream(initial_state_llm, config_llm):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide feedback as needed (same process as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Providing human feedback: 'yes'\n",
      "\n",
      "\n",
      " Document 'employee_handbook.md' flagged for review:\n",
      "   - Reviewed By: Missing - no reviewer name present\n",
      "   - Status: Missing - must be Draft, Final, or Archived\n",
      "   - Version: Missing - must be in semantic version format (e.g., 1.0.0)\n",
      "\n",
      "LLM Analysis:\n",
      "COMPLIANT: no\n",
      "ISSUES:\n",
      "- Reviewed By: Missing - no reviewer name present\n",
      "- Status: Missing - must be Draft, Final, or Archived\n",
      "- Version: Missing - must be in semantic version format (e.g., 1.0.0)\n",
      "\n",
      " Human decision: yes\n",
      "   → Marking as non-compliant\n",
      "\n",
      " Checking with LLM: security_protocols.md\n",
      "Issues found! Flagging for human review...\n",
      "\n",
      " Document 'security_protocols.md' flagged for review:\n",
      "   - Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n",
      "\n",
      "LLM Analysis:\n",
      "COMPLIANT: no\n",
      "ISSUES:\n",
      "- Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n"
     ]
    }
   ],
   "source": [
    "# Provide feedback for any flagged documents\n",
    "# You'll need to run this cell for each document that gets flagged\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Providing human feedback: 'yes'\\n\")\n",
    "\n",
    "for event in compliance_checker_llm.stream(Command(resume=\"yes\"), config_llm):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Providing human feedback: 'yes'\n",
      "\n",
      "\n",
      " Document 'security_protocols.md' flagged for review:\n",
      "   - Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n",
      "\n",
      "LLM Analysis:\n",
      "COMPLIANT: no\n",
      "ISSUES:\n",
      "- Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n",
      "\n",
      " Human decision: yes\n",
      "   → Marking as non-compliant\n"
     ]
    }
   ],
   "source": [
    "# Continue providing feedback for remaining documents\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Providing human feedback: 'yes'\\n\")\n",
    "\n",
    "for event in compliance_checker_llm.stream(Command(resume=\"yes\"), config_llm):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Results\n",
    "\n",
    "Let's see how the LLM version performed compared to pattern matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LLM-ENHANCED COMPLIANCE CHECK COMPLETE\n",
      "============================================================\n",
      "\n",
      "Summary: 1/3 documents compliant\n",
      "\n",
      "COMPLIANT: data_retention.md\n",
      "\n",
      "NON-COMPLIANT: employee_handbook.md\n",
      "  Issues:\n",
      "    - Reviewed By: Missing - no reviewer name present\n",
      "    - Status: Missing - must be Draft, Final, or Archived\n",
      "    - Version: Missing - must be in semantic version format (e.g., 1.0.0)\n",
      "  Human confirmed violation\n",
      "\n",
      "NON-COMPLIANT: security_protocols.md\n",
      "  Issues:\n",
      "    - Reviewed By: \"Legal Team\" does not include a specific reviewer name with first and last name (e.g., \"John Smith\"). A team name is not sufficient to meet the requirement of \"at least one reviewer name (first and last)\"\n",
      "  Human confirmed violation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_state_llm = compliance_checker_llm.get_state(config_llm)\n",
    "results_llm = final_state_llm.values[\"results\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LLM-ENHANCED COMPLIANCE CHECK COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "compliant_count_llm = sum(1 for r in results_llm if r[\"compliant\"])\n",
    "total_count_llm = len(results_llm)\n",
    "\n",
    "print(f\"\\nSummary: {compliant_count_llm}/{total_count_llm} documents compliant\\n\")\n",
    "\n",
    "for result in results_llm:\n",
    "    status = \"COMPLIANT\" if result[\"compliant\"] else \"NON-COMPLIANT\"\n",
    "    print(f\"{status}: {result['filename']}\")\n",
    "    \n",
    "    if not result[\"compliant\"]:\n",
    "        print(\"  Issues:\")\n",
    "        for issue in result[\"issues\"]:\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    if \"human_confirmed\" in result:\n",
    "        if result[\"human_confirmed\"]:\n",
    "            print(\"  Human confirmed violation\")\n",
    "        else:\n",
    "            print(\"  Human marked as false positive\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Why Human-in-the-Loop Matters\n",
    "\n",
    "1. **Accountability**: For compliance and policy enforcement, humans must remain in the decision-making loop\n",
    "2. **Judgment**: Ambiguous cases often require context that only humans have\n",
    "3. **Trust**: Users trust systems more when they can review and override decisions\n",
    "4. **Learning**: Human feedback helps improve the system over time\n",
    "\n",
    "### Pattern Matching vs. LLM\n",
    "\n",
    "**Pattern Matching**:\n",
    "- Pros: Fast, free, deterministic, good for clear-cut rules\n",
    "- Cons: Can't handle ambiguity\n",
    "\n",
    "**LLM-Enhanced**:\n",
    "- Pros: Capable of more nuanced analysis, can understand context\n",
    "- Cons:Costs money (API calls), potentially slower\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "This pattern works for many scenarios:\n",
    "- **Legal/Compliance**: Reviewing contracts, policies, or regulations\n",
    "- **Content Moderation**: Flagging problematic content for human review\n",
    "- **Quality Assurance**: Checking code, documentation, or data quality\n",
    "- **Medical/Healthcare**: Flagging cases that need expert review\n",
    "- **Financial**: Reviewing transactions or documents for approval\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "1. **LangGraph fundamentals**: State, nodes, edges, checkpointers\n",
    "2. **Human-in-the-loop workflows**: Using `interrupt()` and `Command(resume=...)`\n",
    "3. **Iterative development**: Starting simple, then add complexity\n",
    "4. **When to use LLMs**: Trade-offs between pattern matching and LLM analysis\n",
    "5. **Why human oversight matters**: Even smart AI can benefit from human judgment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Want to extend this project? Try:\n",
    "\n",
    "1. **Add more document types**: Support .docx, .pdf, or other formats\n",
    "2. **Implement batch processing**: Check entire directories of documents\n",
    "3. **Add a reporting feature**: Generate PDF or HTML compliance reports\n",
    "4. **Persistent storage**: Use a database to store checkpoints and results\n",
    "5. **Multi-user support**: Allow different reviewers to handle different document types\n",
    "6. **Policy templates**: Allow users to define custom compliance rules\n",
    "7. **Integration**: Connect to document management systems or Slack for notifications\n",
    "\n",
    "## Learn More\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Anthropic API Documentation](https://docs.anthropic.com)\n",
    "- [Search for LangGraph on anaconda.org](https://anaconda.org/search?q=langgraph) to see package details, download stats, and more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
